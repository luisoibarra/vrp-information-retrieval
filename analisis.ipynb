{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las bibliotecas básicas:\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Para evitar los molestos avisos.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('datos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "# Problems with errors\n",
    "zero_time = np.where(data['notape'] <= 1e-17)\n",
    "print(\"Datos con errores\")\n",
    "print(zero_time)\n",
    "data.drop(zero_time[0], inplace = True)\n",
    "\n",
    "# Fixing columns names\n",
    "data.rename(columns={\n",
    "    key: key.strip() for key in data.keys()\n",
    "    }, inplace = True)\n",
    "\n",
    "# Fixing string values\n",
    "for col in data.columns:\n",
    "    if type(data[col][0]) == str:\n",
    "        data[col] = [val.strip() for val in data[col]]\n",
    "        \n",
    "        \n",
    "# Adding problem label\n",
    "data['problem_tag'] = data['problem'].apply(lambda x: x[0])\n",
    "data['optim_routes'] = data['problem'].apply(lambda x: int(x[x.index(\"K\")+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear las variables categóricas a números\n",
    "categoricals_columns= ['problem','criterion']\n",
    "\n",
    "# fetch all values in problem column\n",
    "problem_values = list(set(data['problem'].values))\n",
    "criterion_values = list(set(data['criterion'].values))\n",
    "\n",
    "problem_values.sort()\n",
    "criterion_values.sort()\n",
    "\n",
    "# Por cada valor cambiarlo en el dataframe por su indice en la lista\n",
    "for problem in problem_values:\n",
    "    data['problem'].replace(problem, problem_values.index(problem), inplace=True)\n",
    "for criterion in criterion_values:\n",
    "    data['criterion'].replace(criterion, criterion_values.index(criterion), inplace=True)\n",
    "\n",
    "# Ordenar las columnas con 'tape' , 'notape' y 'ratio' como primeras\n",
    "columns = data.columns.values\n",
    "columns = np.append(['tape','notape','ratio'], columns[~np.in1d(columns, ['tape','notape','ratio'])])\n",
    "data = data[columns]\n",
    "\n",
    "# Eliminar columnas innecesarias para el analisis\n",
    "data.drop(columns=[\"current\", \"total\"], inplace=True) # Current y total no se consideran necesarias\n",
    "\n",
    "# Convertir las variables categóricas en variables ficticias o dummies:\n",
    "\n",
    "# data = pd.get_dummies(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(data):\n",
    "    print(data.describe())\n",
    "    print(data.info())\n",
    "    \n",
    "    plot_boxplot(data, 'ratio')\n",
    "\n",
    "def plot_boxplot(data, key:str):\n",
    "    \"\"\"\n",
    "    Plot a boxplot using the dataframe indexing on key\n",
    "    \"\"\"\n",
    "    plt.boxplot(data[key])\n",
    "    plt.title(f\"Box Plot {key}\")\n",
    "    plt.legend([key])\n",
    "    plt.show()\n",
    "\n",
    "def plot_hist(data, key):\n",
    "    sns.distplot(data[key])\n",
    "\n",
    "def plot_qq(data, key):\n",
    "    stats.probplot(data[key], plot=plt)\n",
    "    plt.show()\n",
    "\n",
    "def plot_corr_scatter_matrix(data, keys, save_fig=None):\n",
    "    sns.set()\n",
    "    sns.pairplot(data[np.array(keys)], size=2.5)\n",
    "    if save_fig:\n",
    "        plt.savefig(save_fig)\n",
    "    plt.show()\n",
    "\n",
    "def iqr(data, key):\n",
    "    \"\"\"\n",
    "    Calculates the IQR from the data associated with key\n",
    "    \"\"\"\n",
    "    Q1 = np.percentile(data[key], 25,\n",
    "                interpolation = 'midpoint')\n",
    "  \n",
    "    Q3 = np.percentile(data[key], 75,\n",
    "                    interpolation = 'midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "    return Q1, Q3, IQR\n",
    "\n",
    "def get_outliers(data, key, upper=True):\n",
    "    \"\"\"\n",
    "    Returns the outliers of data[key]\n",
    "    \"\"\"\n",
    "    Q1, Q3, IQR = iqr(data,key)\n",
    "    if upper:\n",
    "        return data[data[key] >= Q3 + IQR*1.5]\n",
    "    return data[data[key] <= Q1 - IQR*1.5]\n",
    "\n",
    "def remove_outliers(data, key, remove_upper=True, remove_lower=True):\n",
    "    \"\"\"\n",
    "    Returns the data in key without the outliers \n",
    "    \"\"\"\n",
    "    base_data = data\n",
    "    if remove_upper:\n",
    "        base_data = base_data[~base_data.isin(get_outliers(data, key))]\n",
    "    if remove_lower:\n",
    "        base_data = base_data[~base_data.isin(get_outliers(data, key, False))]\n",
    "    return base_data\n",
    "\n",
    "def plot_corr(df, save_fig=None, size=10):\n",
    "    \"\"\"\n",
    "    Function plots a graphical correlation matrix\n",
    "    for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot\n",
    "    \"\"\"\n",
    "\n",
    "    corr = df.corr()\n",
    "    corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n",
    "    fig, ax = plt.subplots(figsize=(size+size/2, size))\n",
    "    \n",
    "    # ax.matshow(corr)\n",
    "    # plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "    # plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    \n",
    "    sns.heatmap(corr,\n",
    "            cmap='coolwarm',\n",
    "            annot=True,\n",
    "            )\n",
    "    \n",
    "    if save_fig:\n",
    "        plt.savefig(save_fig)\n",
    "\n",
    "def plot_scatter_matrix(data, keys:tuple, save_fig=None):\n",
    "    pd.plotting.scatter_matrix(data.loc[:,keys])\n",
    "    if save_fig:\n",
    "        plt.savefig(save_fig)\n",
    "    \n",
    "def plot_grouped_by_boxplot(data, objective, groupby_keys, save_fig=None, **kwargs):\n",
    "    df = pd.DataFrame({str(k): value[objective] for k,value in data[groupby_keys + [objective]].groupby(groupby_keys)})\n",
    "    df.plot(kind='box', title=f\"{objective} boxplot grouped by {', '.join(groupby_keys)}\", **kwargs)\n",
    "    if save_fig:\n",
    "        plt.savefig(save_fig)\n",
    "    plt.show()\n",
    "    \n",
    "def test_anova(data, factor, objective, alpha=0.1):\n",
    "    import scipy.stats as stats\n",
    "    levels = set(data[factor])\n",
    "    levels = [data[objective][data[factor] == level] for level in levels]\n",
    "    result = stats.f_oneway(*levels)\n",
    "    if result.pvalue < alpha:\n",
    "        # H0 is rejected\n",
    "        print(f\"ANOVA: {factor} influences {objective}\")\n",
    "    else:\n",
    "        print(f\"ANOVA: {factor} does not influences {objective}\")\n",
    "    print(result.pvalue)\n",
    "\n",
    "def test_normal_dstribution(data, key, alpha=0.1):\n",
    "    _, pvalue = stats.shapiro(data[key])\n",
    "    if pvalue > alpha:\n",
    "        print(f\"Shappiro test on {key}: Probably Gaussian with pvalue {pvalue}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Shappiro test on {key}: Probably NOT Gaussian with pvalue {pvalue}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimetría y curtosis:\n",
    "\n",
    "print(\"Skewness: %f\" % data['ratio'].skew())\n",
    "print(\"Kurtosis: %f\" % data['ratio'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los datos\n",
    "\n",
    "# corr_data = data.drop(\"criterion\", axis=1)\n",
    "\n",
    "corr_data = data\n",
    "\n",
    "plot_corr(corr_data, save_fig=\"images/correlation.png\")\n",
    "plot_corr_scatter_matrix(corr_data, corr_data.columns, save_fig=\"images/correlation_scatter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers TODO\n",
    "\n",
    "# corr_data = data.drop(\"criterion\", axis=1)\n",
    "\n",
    "corr_data = data\n",
    "\n",
    "## ratio\n",
    "upper_ratio_outliers = get_outliers(corr_data, 'ratio')\n",
    "lower_ratio_outliers = get_outliers(corr_data, 'ratio', False)\n",
    "no_ratio_outliers = remove_outliers(corr_data, \"ratio\")\n",
    "\n",
    "print(\"Upper ratio outliers\")\n",
    "print(upper_ratio_outliers.describe())\n",
    "\n",
    "print(\"Lower ratio outliers\")\n",
    "print(lower_ratio_outliers.describe())\n",
    "\n",
    "print(\"No ratio outliers\")\n",
    "print(no_ratio_outliers.describe())\n",
    "\n",
    "test_normal_dstribution(data, \"ratio\")\n",
    "\n",
    "plot_corr(no_ratio_outliers, save_fig=\"images/correlation_no_ratio_outliers.png\")\n",
    "plot_corr_scatter_matrix(no_ratio_outliers, no_ratio_outliers.columns, save_fig=\"images/correlation_scatter_no_ratio_outliers.png\")\n",
    "\n",
    "plot_corr(upper_ratio_outliers, save_fig=\"images/correlation_upper_ratio_outliers.png\")\n",
    "plot_corr_scatter_matrix(upper_ratio_outliers, corr_data.columns, save_fig=\"images/correlation_scatter_upper_ratio_outliers.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No outliers TODO\n",
    "\n",
    "# corr_data = data.drop(\"criterion\", axis=1)\n",
    "\n",
    "# plot_corr(corr_data, save_fig=\"images/correlation.png\")\n",
    "# plot_corr_scatter_matrix(corr_data, corr_data.columns, save_fig=\"images/correlation_scatter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Trying K-Mean to make clusters and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    " \n",
    "\n",
    "def plot_elbow(data, cluster_range:tuple=(2,20)):\n",
    "    inertias = []\n",
    "    for i in range(*cluster_range):\n",
    "        kmeans = KMeans(n_clusters=i)\n",
    "        kmeans.fit(data)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        # print(f\"Silhouette with {i} clusters: {silhouette_score(data, kmeans.labels_)}\")\n",
    "    \n",
    "    plt.plot(range(*cluster_range), inertias)\n",
    "    plt.title(\"Elbow curve\")\n",
    "    plt.show()\n",
    "\n",
    "def kmeans(data, clusters:int, x_label=None, y_label=None):\n",
    "    \"\"\"\n",
    "    Returns the scaled data annotaed with clusters labels\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler() # StandardScaler()\n",
    "    scale = scaler.fit_transform(data)\n",
    "    scale = pd.DataFrame(scale, columns=data.columns)\n",
    "    \n",
    "    model = KMeans(n_clusters=clusters) # DBSCAN(eps=??, min_samples=??)\n",
    "    clusters = model.fit_predict(scale)\n",
    "    \n",
    "    scale[\"clusters\"] = clusters\n",
    "    return scale\n",
    "\n",
    "def plot_kmeans_clusters(data, labels:tuple):\n",
    "    \"\"\"\n",
    "    Plots the `labels` annotated with `clusters` in data.\n",
    "    \"\"\"\n",
    "    if len(labels) == 2:\n",
    "        sns.scatterplot(x=labels[0], y=labels[1], hue = 'clusters',  data=data, palette='viridis')\n",
    "        plt.show()\n",
    "    if len(labels) == 3:\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlabel(labels[0])\n",
    "        ax.set_ylabel(labels[1])\n",
    "        ax.set_zlabel(labels[2])\n",
    "        ax.set_title(\"Cluster of \" + \", \".join(labels))\n",
    "\n",
    "        scat_plot = ax.scatter(data[labels[0]],data[labels[1]],data[labels[2]], c=data['clusters'])\n",
    "        plt.show()\n",
    "\n",
    "non_obj = data.drop([col for col in data.columns if data[col].dtype == 'O'], axis=1)\n",
    "\n",
    "# Plotting elbow\n",
    "keys = [\"routes\", \"iterations\", \"clients\"] \n",
    "plot_elbow(non_obj[keys])\n",
    "\n",
    "# Elbow method shows that 7-8 clusters are a good choice\n",
    "labeled_normalized_data = kmeans(non_obj, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "# TODO Try with different choices to see what happens\n",
    "keys = [\"routes\", \"iterations\", \"clients\"]\n",
    "plot_kmeans_clusters(labeled_normalized_data, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ratio <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ratio_data = data[data[\"ratio\"] <= 1]\n",
    "\n",
    "print(low_ratio_data.describe())\n",
    "\n",
    "plot_corr_scatter_matrix(low_ratio_data, low_ratio_data.columns, save_fig=\"images/correlation_scatter_ratio_lower_than1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by number of clients and computing the mean for each group\n",
    "remove_out = remove_outliers(data, \"ratio\")\n",
    "\n",
    "computed = remove_out[[\"clients\", \"tape\", \"notape\", \"ratio\"]].groupby([\"clients\"]).mean()\n",
    "print(computed.index)\n",
    "plt.plot(computed.index, computed[\"ratio\"], label=\"ratio\")\n",
    "plt.xlabel(\"clients\")\n",
    "plt.ylabel(\"mean of ratio\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mean_decreasing_ratio.png\")\n",
    "plt.show()\n",
    "plt.plot(computed.index, computed[\"tape\"], label=\"tape\")\n",
    "plt.plot(computed.index, computed[\"notape\"], label=\"notape\")\n",
    "plt.xlabel(\"clients\")\n",
    "plt.ylabel(\"mean of tape/notape\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mean_running_time.png\")\n",
    "plt.show()\n",
    "\n",
    "plot_grouped_by_boxplot(remove_out, \"ratio\", [\"clients\"], save_fig=\"images/boxplot_ratio_groupedby_clients\")\n",
    "# plot_grouped_by_boxplot(data, \"routes\", [\"clients\"])\n",
    "# plot_grouped_by_boxplot(data, \"tape\", [\"clients\"])\n",
    "# plot_grouped_by_boxplot(data, \"notape\", [\"clients\"])\n",
    "\n",
    "plt.scatter(remove_out[\"clients\"], remove_out[\"ratio\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cr in set(data[\"criterion\"]):\n",
    "    print(\"testing anova with criterion\",criterion_values[cr])\n",
    "    anova_data = data[data[\"criterion\"] == cr]\n",
    "    print(len(anova_data))\n",
    "    for col in anova_data.columns :\n",
    "        if col not in [\"criterion\",\"tape\",\"notape\",\"ratio\",\"Index\"]:\n",
    "\n",
    "            test_anova(anova_data, col, \"ratio\")\n",
    "\n",
    "plot_grouped_by_boxplot(data, \"ratio\", [\"criterion\", \"clients\"], save_fig=\"images/boxplot_ratio_groupedby_criterion_cients.png\", figsize=(22,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tape and NoTape Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tape and notape data \n",
    "plt.plot(data.index, data[\"tape\"], label=\"tape\")\n",
    "plt.plot(data.index, data[\"notape\"], label=\"notape\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/tape_vs_notape.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45db824c686f92ff5a2120110a200c79437caa527895339497af8122a932288b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
